\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{subfigure}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Orientation Tracking and Panorama Generation\\

}

\author{\IEEEauthorblockN{1\textsuperscript{st} Pengxi Zeng}
    La Jolla, CA \\
    p2zeng@ucsd.edu}


\maketitle

\begin{abstract}
    This is a report regarding orientation tracking and corresponding panorama generation. It mainly discussed how to
    define the motion model and observation model and utilize the IMU measurements to optimize the rotation quaternions.
    Gradient descent is adopted as the main method for optimization and a combianation of projection-based and normalization-
    based optimization metrics are used to constrain the quaternions to space $\mathbb{H}_*$. The result turns out good for
    most datasets. Finally, the panorama is
    generated using sphere-cylinder projection by first transforming the spherical coordinates of each pixel of the picture from
    camera frame to world frame. The final outcome shows great consistency in space, also indicating good effects of the optimization
    for the quaternions.
\end{abstract}

\begin{IEEEkeywords}
    orientation tracking, panorama, gradient descent
\end{IEEEkeywords}

\section{Introduction}

SLAM, also known as simultaneous localization and mapping, is a technique utilized by autonomous vehicles to 
simultaneously create a map and determine the location of the vehicle within that map. By utilizing SLAM algorithms,
the vehicle can map out unfamiliar environments, allowing engineers to perform tasks like avoiding obstacles and 
planning path using the mapped data. In the SLAM process, the robot repeatedly acquires data from sensors, 
such as cameras or lidars, and uses this data to estimate its own position and to create a map of the environment.
The specific implementation of the SLAM algorithm can vary depending on the sensors and hardware used by the robot,
as well as the specific application and environment in which it operates. Usually due to the noise of the data 
collected, we will adopt methods relying on probabilistic reasoning to optimize the process.


\section{Problem Formulation}
\subsection{Particle-filter SLAM}
Denote $t$ as time, $\boldsymbol{x}_t$ as the robot state at time $t$, $\boldsymbol{u}_t$ as the control input at time $t$,
$\boldsymbol{z}_t$ as the observation at time $t$ and $\boldsymbol{m}_t$ as the map state at time $t$. According to Markov 
assumption, we assume that state $\boldsymbol{x}_{t+1}$ only depends on the previous state $\boldsymbol{x}_t$ and the previous
input $\boldsymbol{u}_t$ and the observation $\boldsymbol{z}_{t+1}$ only depends on the state $\boldsymbol{x}_t$.
Every time, we need to estimate the state of the robot using the motion model and observation model. The general steps are 
dividede into two:
\begin{itemize}
    \item Predict: to use noised motion model to estimate the probability of the robot state $\boldsymbol{x}_{t+1}$.
    \item Update: to use the map data and observation to update the probability of the robot state  $\boldsymbol{x}_{t+1}$.
\end{itemize}
% p_f(\boldsymbol{x}| \boldsymbol{s}, \boldsymbol{u}_t)p_{t|t}(\boldsymbol{s})d\boldsymbol{s}
The process of the predicting and updating is called Bayes filter and could be parametrized in a iterative form:
\begin{equation}
    p_{t+1|t}(\boldsymbol{x}) = \int p_f(\boldsymbol{x}| \boldsymbol{s}, \boldsymbol{u}_t)p_{t|t}(\boldsymbol{s})d\boldsymbol{s},
\end{equation}
\begin{equation}
    p_{t+1|t+1}(\boldsymbol{x}) = \frac{p_h(\boldsymbol{z}_{t+1}|\boldsymbol{x})p_{t+1|t}(\boldsymbol{x})}
    {\int p_h(\boldsymbol{z}_{t+1}|\boldsymbol{s})p_{t+1|t}(\boldsymbol{s}) d\boldsymbol{s}}.
\end{equation}
Considering that the probability space is infinite, it is impossible to implement the continuously represented function. Thus,
we adopt an approximation of the equations: particle filter which descretize the calculation. We could choose $N$ particles to
represent a finite number of the possible states. Thus, we could rewrite the predicting and updating steps as following:
\begin{equation}
    \begin{aligned}
    &p_{t+1 \mid t}\left(\boldsymbol{x}_{t+1}\right)\\ & =\int p_f\left(\boldsymbol{x}_{t+1} \mid \boldsymbol{x}_t, \boldsymbol{u}_t\right) \sum_{k=1}^N \alpha_{t \mid t}[k] \delta\left(\boldsymbol{x}_t-\boldsymbol{\mu}_{t \mid t}[k]\right) d \boldsymbol{x}_t \\
    & =\sum_{k=1}^N \alpha_{t \mid t}[k] p_f\left(\boldsymbol{x}_{t+1} \mid \boldsymbol{\mu}_{t \mid t}[k], \boldsymbol{u}_t\right),
    \end{aligned}
\end{equation}

\begin{equation}
    \begin{aligned}
    &p_{t+1 \mid t+1}\left(\boldsymbol{x}_{t+1}\right) 
    \\&=\sum_{k=1}^N\left[\frac{\alpha_{t+1 \mid t}[k] p_h\left(\boldsymbol{z}_{t+1} \mid \boldsymbol{\mu}_{t+1 \mid t}[k]\right)}{\sum_{j=1}^N \alpha_{t+1 \mid t}[j] p_h\left(\boldsymbol{z}_{t+1} \mid \boldsymbol{\mu}_{t+1 \mid t}[j]\right)}\right] 
    \\ &\delta\left(\boldsymbol{x}_{t+1}-\boldsymbol{\mu}_{t+1 \mid t}[k]\right),
    \end{aligned}
\end{equation}
where $\boldsymbol{\mu}[k]$ denotes the state of the $k$-th robot at time $t$ and $\alpha[k]$ the probability. In the predicting step, the
weights of the particles remain unchanged and in the updating step, the states of the particles remain unchanged.

\subsection{Texture Map}


\section{Technical Approach}
\subsection{Orientation Tracking}


\subsection{Panorama Generation}

\section{Results}
\subsection{Orientation Tracking}
From the results, we can find out that for most of the datasets, angles of Roll and Pitch match with real data realtively
well, but for Yaw, the shape of optimized results match with that of the real data, while the is a gap between them. One
guess is that the accumulation of the error in Yaw could not be well eliminated.

\subsection{Panorama}
From the results we can tell that the pictures have the consistency in space, e.g. the connection of the handrail.


\end{document}
